# -*- coding: utf-8 -*-
"""python_word_clooud.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qZ2eyvGfFX60qCpvf_sacd0YbV19jhG6
"""

from google.colab import drive
drive.mount('/content/drive')

import os 
project = '100knock-process-visualization'
chapter = 4
os.chdir(f'/content/drive/MyDrive/{project}/chapter-{chapter}/')

ls data/

with open('data/hashire_merosu.txt', mode='r', encoding='shift-jis') as f:
  content = f.read()
print(content)

content = ' '.join(content.split())
content

import unicodedata
content = unicodedata.normalize('NFKC', content)
content

import re
pattern = re.compile(r'^.+(#地から1字上げ].+#地から1字上げ]).+$')
body = re.match(pattern, content).group(1)
print(body)

body = body.replace('#地から1字上げ] ------------------------------------------------------- ', '')
body = body.replace(' [#地から1字上げ]', '')
body

with open('data/hashire_merosu.txt', mode='r', encoding='shift-jis') as f:
  content = f.readlines()
content

# Commented out IPython magic to ensure Python compatibility.
# %%bash
# 
# apt install -yq \
#   mecab \
#   mecab-ipadic-utf8 \
#   libmecab-dev
# pip install -q mecab-python3==0.996.5
# ln -s /etc/mecabrc /usr/local/etc/mecabrc

pip list | grep mecab

import MeCab
tagger = MeCab.Tagger()
body = booklist.iloc[0, 4]
parsed = tagger.parse(body).split('\n')
parsed[:4]

parsed[-4:]

parsed = parsed[:-2]
parsed[-4:]

*values, = map(lambda s: re.split(r'\t|,', s), parsed)
values[:4]

import pandas as pd
columns = ['表層形', '品詞', '品詞細分類1', '品詞細分類2', '品詞細分類3', '活用型', '活用形', '原形', '読み', '発音']
mecab_df = pd.DataFrame(data=values, columns=columns)
print(len(mecab_df))
mecab_df.head(4)

print(mecab_df.groupby(['原形','品詞']).size().sort_values(ascending=False))

noun = mecab_df.loc[mecab_df['品詞'] == '名詞']
noun

verb = mecab_df.loc[(mecab_df['品詞'] == '名詞')|(mecab_df['品詞'] == '動詞')]
verb

with open('data/stop_words.txt', mode='r') as f:
  stop_words = f.read().split()
stop_words

print(len(noun))
noun = noun.loc[~noun['原形'].isin(stop_words)] 
print(len(noun))
display(noun.head())

print(len(verb))
verb = verb.loc[~verb['原形'].isin(stop_words)] 
print(len(verb))
display(verb.head())

count = noun.groupby('原形').size().sort_values(ascending=False)
count.name = 'count'
count = count.reset_index().head(10)
count

!pip install -q japanize-matplotlib

import matplotlib.pyplot as plt
import seaborn as sns
import japanize_matplotlib
plt.figure(figsize=(10, 5))
sns.barplot(x=count['count'], y=count['原形'])

!apt-get -yq install fonts-ipafont-gothic

ls /usr/share/fonts/opentype/ipafont-gothic

from wordcloud import WordCloud 
import matplotlib.pyplot as plt
import japanize_matplotlib
font_path = 'usr/share/fonts/opentype/ipafont-gothic/ipagp.ttf'
cloud = WordCloud(background_color='white', font_path=font_path).generate(' '.join(noun['原形'].values))
plt.figure(figsize=(10, 5))
plt.imshow(cloud)
plt.axis("off")
plt.savefig('data/wc_noun_base_2.png')
plt.show()

cloud = WordCloud(background_color='white', font_path=font_path, regexp="[\w']+").generate(' '.join(noun['原形'].values))
plt.figure(figsize=(10, 5))
plt.imshow(cloud)
plt.axis("off")
plt.savefig('data/wc_noun_base_1.png')
plt.show()

cloud = WordCloud(background_color='white', font_path=font_path).generate(' '.join(noun['表層形'].values))
plt.figure(figsize=(10, 5))
plt.imshow(cloud)
plt.axis("off")
plt.savefig('data/wc_noun_surface.png')
plt.show()

cloud = WordCloud(background_color='white', font_path=font_path).generate(' '.join(verb['原形'].values))
plt.figure(figsize=(10, 5))
plt.imshow(cloud)
plt.axis("off")
plt.savefig('data/wc_noun-verb_base.png')
plt.show()

target = mecab_df['表層形'].to_list()
len(target)

from nltk import ngrams
bigram = ngrams(target, 2)

import collections
counter = collections.Counter(bigram)
print(counter)